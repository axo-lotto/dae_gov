# Context Window Scalability Assessment
## November 14, 2025

---

## ðŸŽ¯ Overview

**Question:** How scalable is our context window as entity memory grows?

**Answer:** Very scalable! Here's the complete analysis.

---

## ðŸ“Š Current Context Window Architecture

### LLM Configuration

**Model:** Ollama (llama3.2 or similar)
**Max Output Tokens:** 150 tokens (configured in `Config.LOCAL_LLM_MAX_TOKENS`)
**Context Window:** Depends on model, typically **2048-8192 tokens** for llama3.2

### Entity Context String Format

```
Known information:
- User's name: Sarah
- Daughter's name: Emma
- Daughter's name: Lily
- User's favorite color: blue
- User's career: therapist
...
```

**Token Cost per Entity:** ~10-15 tokens (on average)

---

## ðŸ”¢ Scalability Math

### Current System Capacity

**Scenario:** User with 100 entities stored

**Calculation:**
```
Entity context string:
- Header: "Known information:\n" = ~5 tokens
- Per entity: "- User's X: Y\n" = ~10-15 tokens
- 100 entities Ã— 12 tokens (avg) = 1200 tokens
- Total: ~1205 tokens
```

**LLM Prompt Structure:**
```
System prompt: ~150 tokens
Entity context: ~1205 tokens
Organ lures: ~200 tokens
User input: ~50 tokens
Instructions: ~100 tokens
-----------------------------------
Total input: ~1705 tokens
```

**Remaining for output:** ~343 tokens (if 2048 context window)

**Verdict:** âœ… System can handle 100 entities comfortably!

---

### Maximum Theoretical Capacity

**Model Context Windows:**
- llama3.2:1b â†’ 2048 tokens
- llama3.2:3b â†’ 8192 tokens
- llama3:8b â†’ 8192 tokens
- llama3:70b â†’ 8192 tokens

**Maximum Entities (2048 context):**
```
Available for entities: 2048 - 500 (other prompt) = 1548 tokens
Max entities: 1548 / 12 = ~129 entities
```

**Maximum Entities (8192 context):**
```
Available for entities: 8192 - 500 (other prompt) = 7692 tokens
Max entities: 7692 / 12 = ~640 entities
```

**Verdict:** âœ… Can scale to hundreds of entities!

---

## ðŸ§ª Testing Strategy

### Entity Epoch Training Tests

**What We Measure:**
1. **Context Window Growth** - Track tokens per turn as entities accumulate
2. **Processing Time** - Ensure no degradation with more entities
3. **Entity Recall Accuracy** - Verify LLM can still find entities in large context
4. **Memory Consistency** - Check entity persistence across turns/epochs

### Test Scenarios (from entity_memory_training_pairs.json)

**Scenario 1: Basic Name (3 turns)**
- Turn 1: Introduce name â†’ 1 entity
- Turn 2: Use name â†’ 1 entity context
- Turn 3: Recall name â†’ 1 entity context
- **Context growth:** 1 entity = ~15 tokens

**Scenario 2: Family Relationships (5 turns)**
- Introduces 2 daughters, tracks relationships
- **Context growth:** 3 entities = ~40 tokens

**Scenario 3: Complex Multi-Entity (5 turns)**
- Name, partner, children, career, preferences
- **Context growth:** 8+ entities = ~100 tokens

**Scenario 4: Crisis vs Healing Context (7 turns)**
- TSK-enriched scenarios with entity memory
- Tests entity recall under polyvagal state changes

**Scenario 5: Entity Updates (5 turns)**
- Update existing entities, handle conflicts
- Tests entity modification and persistence

**Total:** 5 scenarios, 25 turns, ~15-20 entities max

---

## ðŸ“ˆ Metrics We Track

### Per-Turn Metrics

```python
context_window_metrics = {
    'character_count': len(entity_context_string),
    'line_count': entity_context_string.count('\n'),
    'entity_count': entity_context_string.count('- '),
    'estimated_tokens': len(entity_context_string.split())
}
```

### Per-Epoch Metrics

```python
epoch_metrics = {
    'mean_context_tokens': float,  # Average across all turns
    'max_context_tokens': float,   # Peak context window
    'max_entity_count': int,       # Most entities in one turn
    'entity_recall_accuracy': float,  # % correct recalls
    'mean_processing_time': float  # Average per turn
}
```

### Multi-Epoch Evolution

```python
evolution_metrics = {
    'context_window_evolution': [
        {'epoch': 1, 'mean_tokens': X, 'max_tokens': Y, 'max_entities': Z},
        ...
    ],
    'entity_recall_evolution': [
        {'epoch': 1, 'accuracy': 0.85},
        ...
    ]
}
```

---

## ðŸš€ Running Entity Epoch Training

### Quick Test (1 epoch)

```bash
export PYTHONPATH="/Users/daedalea/Desktop/DAE_HYPHAE_1":$PYTHONPATH
python3 training/entity_epoch_trainer.py --epochs 1
```

**Output:**
- Entity recall accuracy per scenario
- Context window metrics per turn
- Processing time per turn
- Final summary with scalability analysis

### Full Training (5 epochs)

```bash
python3 training/entity_epoch_trainer.py --epochs 5
```

**Output:**
- 5 epochs Ã— 5 scenarios Ã— 5 turns avg = 125 total turns
- Context window evolution across epochs
- Entity recall accuracy evolution
- R-matrix learning (TSK adaptation)
- Results saved to `results/entity_training/`

### Custom Configuration

```bash
python3 training/entity_epoch_trainer.py \
    --epochs 10 \
    --corpus knowledge_base/entity_memory_training_pairs.json \
    --results-dir results/custom_entity_training
```

---

## ðŸ” What We Learn

### 1. Context Window Scalability

**Questions Answered:**
- How many tokens does each entity add?
- Does processing slow down with more entities?
- Can LLM still find entities in large context?
- What's the practical limit before degradation?

**Expected Results:**
- Linear growth: ~12 tokens per entity
- Minimal processing impact (entity context is just string concatenation)
- LLM attention handles up to ~100 entities well
- Degradation likely beyond 200 entities (attention dilution)

### 2. Entity Recall Accuracy

**Questions Answered:**
- Does DAE correctly extract entities from user input?
- Does DAE recall entities across turns?
- Does entity recall work in all emission paths?
- Does TSK learning improve entity handling?

**Expected Results:**
- Extraction: 95%+ accuracy (organ-prehension based)
- Recall (direct path): 90%+ accuracy
- Recall (hebbian fallback): 85%+ accuracy (now fixed!)
- TSK improvement: 5-10% over epochs

### 3. Multi-Turn Consistency

**Questions Answered:**
- Do entities persist across conversation turns?
- Do entity updates propagate correctly?
- Do relationships maintain coherence?
- Does memory survive polyvagal state changes?

**Expected Results:**
- Persistence: 100% (stored in user_state.json)
- Updates: 95%+ correct propagation
- Relationship coherence: 90%+
- Polyvagal resilience: 85%+ (tested in Scenario 4)

---

## ðŸ’¡ Optimization Strategies

### If Context Window Becomes Issue

**Strategy 1: Selective Entity Loading**
```python
# Load only relevant entities based on query
relevant_entities = filter_entities_by_relevance(
    all_entities,
    user_input,
    max_entities=50
)
```

**Strategy 2: Entity Summarization**
```python
# Compress entity context for long lists
if len(entities) > 100:
    entity_context = summarize_entities(entities)
```

**Strategy 3: Tiered Memory**
```python
# Tier 1: Recent/important (always loaded)
# Tier 2: Contextual (load if relevant)
# Tier 3: Archive (load on explicit request)
```

**Strategy 4: Larger Context Model**
```python
# Upgrade to model with 8K+ context
Config.LOCAL_LLM_MODEL = 'llama3:8b'  # 8192 tokens
```

**Current Status:** None needed! System handles current scale well.

---

## ðŸ“Š Benchmark Results (Projected)

### Expected Performance (5 scenarios, 25 turns)

| Metric | Epoch 1 | Epoch 5 | Change |
|--------|---------|---------|--------|
| Entity recall accuracy | 75% | 90% | +15% |
| Mean context tokens | 35 | 55 | +20 |
| Max context tokens | 120 | 140 | +20 |
| Max entities | 8 | 10 | +2 |
| Mean processing time | 0.15s | 0.16s | +0.01s |

**Analysis:**
- âœ… Context window grows linearly (predictable)
- âœ… Processing time stays constant (scalable)
- âœ… Entity recall improves with training (TSK learning works)
- âœ… System comfortable with 10-20 entities

---

## ðŸŽ¯ Practical Limits

### Recommended Operating Range

**Optimal:** 1-50 entities per user
- Fast processing
- High recall accuracy
- Clear context window
- Excellent UX

**Comfortable:** 50-150 entities per user
- Slight processing overhead
- Good recall accuracy
- Manageable context window
- Good UX

**Maximum:** 150-300 entities per user
- Noticeable processing time
- Recall accuracy may degrade
- Context window near limits
- May need optimization

**Beyond 300:** Requires tiered memory strategy

---

## ðŸ”® Future Enhancements

### Entity Memory V2

**Features:**
1. **Semantic Entity Clustering**
   - Group related entities
   - Load clusters instead of individual entities
   - Reduce context window bloat

2. **Entity Importance Scoring**
   - Track entity usage frequency
   - Prioritize important entities in context
   - Archive rarely-used entities

3. **Temporal Entity Relevance**
   - Recent entities loaded first
   - Older entities loaded on relevance
   - Time-aware entity filtering

4. **Entity Compression**
   - Multi-value entities compressed
   - Relationship graphs instead of lists
   - Hierarchical entity structures

---

## ðŸ“ Files

**Training Runner:**
- `training/entity_epoch_trainer.py` - Main training script

**Training Data:**
- `knowledge_base/entity_memory_training_pairs.json` - 5 scenarios, 25 turns

**Results:**
- `results/entity_training/` - Epoch results and metrics

**Config:**
- `config.py` - `LOCAL_LLM_MAX_TOKENS = 150` (output limit)

---

## ðŸš€ Next Steps

### 1. Run Pilot Test (1 epoch)

```bash
export PYTHONPATH="/Users/daedalea/Desktop/DAE_HYPHAE_1":$PYTHONPATH
python3 training/entity_epoch_trainer.py --epochs 1
```

**Goal:** Verify training pipeline works end-to-end

### 2. Run Full Training (5 epochs)

```bash
python3 training/entity_epoch_trainer.py --epochs 5
```

**Goal:** Measure entity recall improvement and context scalability

### 3. Analyze Results

```bash
cat results/entity_training/entity_epoch_training_*.json | jq '.summary'
```

**Goal:** Extract insights on scalability and accuracy

### 4. Optimize (if needed)

Based on results, implement:
- Selective entity loading (if context > 1000 tokens)
- Entity importance scoring (if accuracy < 80%)
- Larger context model (if hitting limits)

---

**Last Updated:** November 14, 2025
**Status:** ðŸŸ¢ READY TO TRAIN
**Context Window:** Highly scalable (100+ entities comfortable)
**Training Corpus:** 5 scenarios, 25 turns, entity-focused
**Expected Accuracy:** 85-95% after training

---

ðŸŒ€ **"Context window is not a bottleneck. Entity recall is ready to scale!"** ðŸŒ€
