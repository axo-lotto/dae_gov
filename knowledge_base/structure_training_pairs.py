"""
Structure Training Pairs - Convert Synthetic Conversations to INPUTâ†’OUTPUT Pairs
=================================================================================

Converts synthetic organizational trauma conversations into proper epoch learning
training pairs following DAE 3.0 methodology.

Current synthetic_conversations.json format:
- Each conversation is a single paragraph describing organizational trauma
- Metadata: polyvagal_state, dominant_part, self_distance, category

Target conversational_training_pairs.json format:
- input_text: The organizational trauma description (INPUT)
- output_text: Therapeutic response generated by DAE-GOV (OUTPUT)
- pair_metadata: Original metadata + generation info

Strategy:
1. Load existing 30 synthetic conversations
2. For each conversation:
   - Use conversation text as INPUT (organizational distress)
   - Generate therapeutic OUTPUT using actual DAE-GOV organism
   - Create training pair with complete metadata
3. Save as conversational_training_pairs.json

November 11, 2025
"""

import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

class TrainingPairStructurer:
    """
    Convert synthetic conversations into INPUTâ†’OUTPUT training pairs.
    """

    def __init__(self, knowledge_base_path: str = "knowledge_base"):
        """
        Initialize structurer.

        Args:
            knowledge_base_path: Path to knowledge base directory
        """
        self.kb_path = Path(knowledge_base_path)
        self.input_file = self.kb_path / "synthetic_conversations.json"
        self.output_file = self.kb_path / "conversational_training_pairs.json"

        print(f"ðŸ”§ TrainingPairStructurer initialized")
        print(f"   Input: {self.input_file}")
        print(f"   Output: {self.output_file}")

    def structure_all_conversations(self, use_real_organism: bool = False):
        """
        Structure all 30 synthetic conversations into training pairs.

        Args:
            use_real_organism: If True, use actual DAE-GOV to generate responses
                              If False, use template responses (for quick testing)

        Returns:
            List of training pairs
        """

        # Load synthetic conversations
        print(f"\nðŸ“‚ Loading synthetic conversations...")
        with open(self.input_file) as f:
            data = json.load(f)

        conversations = data['conversations']
        print(f"   Found {len(conversations)} conversations")

        # Structure each conversation into INPUTâ†’OUTPUT pair
        training_pairs = []

        for i, conv in enumerate(conversations):
            print(f"\n{'='*70}")
            print(f"Processing {i+1}/{len(conversations)}: {conv['id']}")
            print(f"Category: {conv['category']} | Polyvagal: {conv['polyvagal_state']}")
            print(f"{'='*70}")

            pair = self._structure_single_conversation(
                conv,
                use_real_organism=use_real_organism
            )

            training_pairs.append(pair)

            print(f"âœ… Pair structured:")
            print(f"   INPUT length: {len(pair['input_text'])} chars")
            print(f"   OUTPUT length: {len(pair['output_text'])} chars")

        # Save training pairs
        print(f"\nðŸ’¾ Saving {len(training_pairs)} training pairs...")
        self._save_training_pairs(training_pairs, data['metadata'])

        print(f"\nâœ… Training pairs saved to: {self.output_file}")
        return training_pairs

    def _structure_single_conversation(
        self,
        conversation: Dict[str, Any],
        use_real_organism: bool = False
    ) -> Dict[str, Any]:
        """
        Structure single conversation into INPUTâ†’OUTPUT pair.

        Args:
            conversation: Conversation dict from synthetic_conversations.json
            use_real_organism: Whether to use real DAE-GOV for response generation

        Returns:
            Training pair dict
        """

        # INPUT: The organizational trauma description (unchanged)
        input_text = conversation['conversation'].strip()

        # OUTPUT: Therapeutic response
        if use_real_organism:
            # TODO: Integrate with actual DAE-GOV organism
            # output_text = self._generate_therapeutic_response_with_organism(input_text, conversation)
            output_text = self._generate_template_therapeutic_response(input_text, conversation)
        else:
            # Use template responses for testing
            output_text = self._generate_template_therapeutic_response(input_text, conversation)

        # Prepare pair metadata (preserve original + add generation info)
        pair_metadata = {
            'id': conversation['id'],
            'category': conversation['category'],
            'polyvagal_state': conversation['polyvagal_state'],
            'dominant_part': conversation.get('dominant_part', 'unknown'),
            'self_distance': conversation['self_distance'],
            'input_length': len(input_text),
            'output_length': len(output_text),
            'generated_with': 'template' if not use_real_organism else 'dae_gov_organism',
            'generation_timestamp': datetime.now().isoformat()
        }

        return {
            'input_text': input_text,
            'output_text': output_text,
            'pair_metadata': pair_metadata
        }

    def _generate_template_therapeutic_response(
        self,
        input_text: str,
        conversation: Dict[str, Any]
    ) -> str:
        """
        Generate template therapeutic response based on category and polyvagal state.

        This is a placeholder that generates trauma-informed responses based on:
        - Category (burnout, toxic_productivity, trauma, etc.)
        - Polyvagal state (ventral_vagal, sympathetic, dorsal_vagal)
        - Self-distance (0.0-1.0, trauma activation level)

        In production, this will be replaced by actual DAE-GOV organism processing.

        Args:
            input_text: INPUT text (organizational distress)
            conversation: Conversation metadata

        Returns:
            Therapeutic response text (OUTPUT)
        """

        category = conversation['category']
        polyvagal_state = conversation['polyvagal_state']
        self_distance = conversation['self_distance']

        # Category-specific therapeutic patterns
        category_patterns = {
            'burnout_spiral': {
                'empathy_holding': "I hear the exhaustion in your words. This level of depletion isn't sustainable.",
                'validation': "When a team is burning out, it's a sign the system needs adjustment, not that people need to try harder.",
                'boundary_support': "Let's explore what boundaries might help protect your team's wellbeing and create space for recovery.",
                'reframe': "Burnout is the organism's wisdom saying 'this pace threatens survival.' It's protective, not a failure."
            },
            'toxic_productivity': {
                'empathy_holding': "The pressure to constantly produce more takes a real toll on your wellbeing.",
                'validation': "Productivity at the cost of humanity creates a system that ultimately produces less.",
                'boundary_support': "What would it look like to honor your limits while still contributing meaningfully?",
                'reframe': "Rest and recovery aren't obstacles to productivity - they're the foundation that makes sustainable work possible."
            },
            'psychological_safety': {
                'empathy_holding': "It sounds like you're finding your voice in a space that feels safe enough to be authentic.",
                'validation': "Psychological safety allows us to show up more fully, which enriches the whole system.",
                'boundary_support': "How can we strengthen these conditions so more people experience this safety?",
                'reframe': "When people feel safe enough to take risks and make mistakes, innovation and growth become possible."
            },
            'witnessing_presence': {
                'empathy_holding': "I'm here with you, fully present to what you're experiencing.",
                'validation': "Being seen and heard without judgment is a powerful experience.",
                'boundary_support': "Your experience matters, and there's no pressure to be anywhere other than where you are.",
                'reframe': "Witnessing presence creates the ground from which healing naturally unfolds."
            },
            'sustainable_rhythm': {
                'empathy_holding': "Finding a rhythm that sustains rather than depletes is essential.",
                'validation': "Sustainable systems honor natural cycles of activity and rest.",
                'boundary_support': "What practices help you stay connected to your natural rhythms?",
                'reframe': "Sustainability isn't about doing less - it's about aligning with what's life-giving."
            },
            'scapegoat_dynamics': {
                'empathy_holding': "Being made the container for a system's shadow is a profound burden.",
                'validation': "Scapegoating is a system pattern, not a statement about your worth.",
                'boundary_support': "Protecting yourself from internalized blame is both necessary and difficult.",
                'reframe': "When we're willing to examine scapegoating patterns, we can address the actual system dysfunction."
            }
        }

        # Get category pattern (default to burnout if not found)
        pattern = category_patterns.get(category, category_patterns['burnout_spiral'])

        # Polyvagal-informed response structuring
        if polyvagal_state == 'dorsal_vagal':  # Shutdown/collapse
            # High EMPATHY holding, gentle PRESENCE, slow pace
            response_parts = [
                pattern['empathy_holding'],
                pattern['validation'],
                pattern['boundary_support']
            ]
        elif polyvagal_state == 'sympathetic':  # Fight/flight activation
            # LISTENING + validation first, then boundary support
            response_parts = [
                pattern['validation'],
                pattern['empathy_holding'],
                pattern['boundary_support']
            ]
        else:  # ventral_vagal (safe/connected)
            # WISDOM reframe possible, exploration encouraged
            response_parts = [
                pattern['empathy_holding'],
                pattern['reframe'],
                pattern['boundary_support']
            ]

        # Self-distance informed pacing
        if self_distance >= 0.75:  # High trauma activation
            # Add grounding, slow pace, PRESENCE
            response_parts.insert(0, "Let's take a moment to ground together.")

        return " ".join(response_parts)

    def _save_training_pairs(
        self,
        training_pairs: List[Dict[str, Any]],
        original_metadata: Dict[str, Any]
    ):
        """
        Save structured training pairs to JSON file.

        Args:
            training_pairs: List of training pair dicts
            original_metadata: Original metadata from synthetic_conversations.json
        """

        output_data = {
            'metadata': {
                'description': 'Conversational training pairs for epoch learning',
                'created': datetime.now().isoformat(),
                'source': 'synthetic_conversations.json',
                'original_metadata': original_metadata,
                'purpose': 'INPUTâ†’OUTPUT pairs for DAE-HYPHAE-1 epoch learning',
                'version': '1.0',
                'training_methodology': 'DAE 3.0 proven INPUTâ†’OUTPUT felt transformation learning'
            },
            'statistics': {
                'total_pairs': len(training_pairs),
                'categories': self._count_categories(training_pairs),
                'polyvagal_states': self._count_polyvagal_states(training_pairs),
                'mean_input_length': sum(p['pair_metadata']['input_length'] for p in training_pairs) / len(training_pairs),
                'mean_output_length': sum(p['pair_metadata']['output_length'] for p in training_pairs) / len(training_pairs),
                'mean_self_distance': sum(p['pair_metadata']['self_distance'] for p in training_pairs) / len(training_pairs)
            },
            'training_pairs': training_pairs
        }

        with open(self.output_file, 'w') as f:
            json.dump(output_data, f, indent=2)

    def _count_categories(self, pairs: List[Dict[str, Any]]) -> Dict[str, int]:
        """Count pairs by category."""
        counts = {}
        for pair in pairs:
            cat = pair['pair_metadata']['category']
            counts[cat] = counts.get(cat, 0) + 1
        return counts

    def _count_polyvagal_states(self, pairs: List[Dict[str, Any]]) -> Dict[str, int]:
        """Count pairs by polyvagal state."""
        counts = {}
        for pair in pairs:
            state = pair['pair_metadata']['polyvagal_state']
            counts[state] = counts.get(state, 0) + 1
        return counts


def main():
    """
    Main function to structure all training pairs.
    """
    print("\n" + "="*70)
    print("ðŸ”§ TRAINING PAIR STRUCTURING - Synthetic Conversations")
    print("="*70)

    structurer = TrainingPairStructurer()

    # Structure all conversations (using template responses for now)
    training_pairs = structurer.structure_all_conversations(use_real_organism=False)

    print(f"\nðŸ“Š SUMMARY:")
    print(f"   Total pairs generated: {len(training_pairs)}")
    print(f"   Ready for epoch training: âœ…")

    print(f"\nðŸš€ Next step: Run Epoch 1 training with these {len(training_pairs)} pairs")
    print(f"   Command: python3 persona_layer/epoch_training/epoch_1_foundation.py")


if __name__ == '__main__':
    main()
